{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERTmoji.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2c4e9e26d8754495b5b9f8c899b73576": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d6d6e91623a64527a97a3be80e15e93b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5c591b1556c7461cbc0531fae0daff0a",
              "IPY_MODEL_9fabd0e9e4e84155b5054ff53641cd39"
            ]
          }
        },
        "d6d6e91623a64527a97a3be80e15e93b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c591b1556c7461cbc0531fae0daff0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c9067d92e1924a359d28b84bc45ab302",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bc310820b9b14d2b81e1e3b8a4d14be4"
          }
        },
        "9fabd0e9e4e84155b5054ff53641cd39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f420bdef198d48f4b0053c6e3adeefb5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.28MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a36afb25d30d4e0ba11968c4327bffc0"
          }
        },
        "c9067d92e1924a359d28b84bc45ab302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bc310820b9b14d2b81e1e3b8a4d14be4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f420bdef198d48f4b0053c6e3adeefb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a36afb25d30d4e0ba11968c4327bffc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c832d0f1f8094f9289c89b147f04289b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b3a454c12d4f451191fcbf787a57dad8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_610b6e23d680404da2272ecf11daabd6",
              "IPY_MODEL_20548c57241443859bd6e408e7c497da"
            ]
          }
        },
        "b3a454c12d4f451191fcbf787a57dad8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "610b6e23d680404da2272ecf11daabd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dab2d9b73e4440b0ba428e757cd5ead1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_747ab219467b47ba9bb7381c8bf08685"
          }
        },
        "20548c57241443859bd6e408e7c497da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d03d3541c4e64133a795d99a8f89ac6a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 159B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_267b2070c1d54261a0877ecbb5103fa6"
          }
        },
        "dab2d9b73e4440b0ba428e757cd5ead1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "747ab219467b47ba9bb7381c8bf08685": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d03d3541c4e64133a795d99a8f89ac6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "267b2070c1d54261a0877ecbb5103fa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae6e17b3191c45ec8d332e5944416387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7dd3611e1834457a9118f4b1b4691195",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8d844d67ce0d4221bf0f0d0d82feb67a",
              "IPY_MODEL_76e23b8122034d71a559b1a15b1ab481"
            ]
          }
        },
        "7dd3611e1834457a9118f4b1b4691195": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d844d67ce0d4221bf0f0d0d82feb67a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_96dc99cea03c43df8c428351e6ccf218",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_47149a8fdd0842d98f9c0dc69e6fa6bf"
          }
        },
        "76e23b8122034d71a559b1a15b1ab481": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dd4f9b9bfae04b858d2aff987f8b8d81",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 5.56MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b88623741d945e89531faf75b3cb061"
          }
        },
        "96dc99cea03c43df8c428351e6ccf218": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "47149a8fdd0842d98f9c0dc69e6fa6bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dd4f9b9bfae04b858d2aff987f8b8d81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b88623741d945e89531faf75b3cb061": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fd130b751e99427a94ea2cb200b1345e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_97780080c045416bb10388f8bcb78053",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_833acc0d13344263be068a9c7214a2ed",
              "IPY_MODEL_6f9613b9dd144a65a73109f707f4e197"
            ]
          }
        },
        "97780080c045416bb10388f8bcb78053": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "833acc0d13344263be068a9c7214a2ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_94bbb9af17394e2b935d17e81838f444",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 442,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 442,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fc98a6276f7d4c00a911adc510e67df9"
          }
        },
        "6f9613b9dd144a65a73109f707f4e197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_638ff42ad4284cbca74a2c93759f610b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 442/442 [00:27&lt;00:00, 16.1B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_119532ca96af403a8e71fb5922ca3cf5"
          }
        },
        "94bbb9af17394e2b935d17e81838f444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fc98a6276f7d4c00a911adc510e67df9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "638ff42ad4284cbca74a2c93759f610b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "119532ca96af403a8e71fb5922ca3cf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa2800ef078a4e2a84d3d9062f47da10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e7836dc15c364084bbf635f7f3adee7a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_002d07f0eb064d3faaa4ea7f863dc969",
              "IPY_MODEL_9dd08423806a48c0b22ad731113e30bd"
            ]
          }
        },
        "e7836dc15c364084bbf635f7f3adee7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "002d07f0eb064d3faaa4ea7f863dc969": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7c5eaf4fc1824b5a9bd6eccd8be9b30c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 267967963,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 267967963,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9bdcdee77681492e95033d7894a400a2"
          }
        },
        "9dd08423806a48c0b22ad731113e30bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a2858b3aaa6a4136a52b1dd3e57362fa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 268M/268M [00:05&lt;00:00, 51.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_28463dc7ea46415c8afa976b194ae9fc"
          }
        },
        "7c5eaf4fc1824b5a9bd6eccd8be9b30c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9bdcdee77681492e95033d7894a400a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a2858b3aaa6a4136a52b1dd3e57362fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "28463dc7ea46415c8afa976b194ae9fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSKU4vvwrkgc"
      },
      "source": [
        "#BERTmoji\n",
        "\n",
        "### imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTzC1mgRmWdK"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "from pathlib import Path\n",
        "import time\n",
        "import random\n",
        "\n",
        "# Check if we are running on a CPU or GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWmhlyh7DJK0"
      },
      "source": [
        "We need to install the transformers library first, if we use Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoyOsBDdmpHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cb49588-fae5-46b7-c40a-2bcb187c39f9"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 41.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 40.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNiuqmnMDTG3"
      },
      "source": [
        "From transformers, we need only the model itself, which is `DistilBertForSequenceClassification`; special optimizer that works with it, which is `AdamW`; and a pretrained tokenizer `DistilBertTokenizer` to feed our data correctly into the model. \n",
        "\n",
        "For the sake of saving space and performance, we use `DistilBert` in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI2RRh0anNai"
      },
      "source": [
        "from transformers import DistilBertForSequenceClassification, AdamW, DistilBertConfig\n",
        "from transformers import DistilBertTokenizer\n",
        "from transformers import get_linear_schedule_with_warmup"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox9JncIamvf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88f6a653-0826-49c9-99af-caa7a1fa5f14"
      },
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "#folds \n",
        "#dataas = \"content/drive/My Drive/NLP/Data\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spQX_Etum1-F"
      },
      "source": [
        "## Emoji def pred data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "36P62CtDm5LR",
        "outputId": "2812f816-7b49-4af8-be99-f5e8a796d5b5"
      },
      "source": [
        "import json\n",
        "def make_uchr(code: str):\n",
        "  return chr(int(code.lstrip(\"U+\").zfill(8), 16))\n",
        "\n",
        "lines_def = []\n",
        "emojis = []\n",
        "def_path = \"/content/drive/My Drive/NLP/emojis.json\"\n",
        "\n",
        "\n",
        "with open(file = def_path) as f:\n",
        "  def_data = pd.DataFrame.from_dict(json.load(f))\n",
        "def_data = def_data.drop([\"category\",\"name\", \"senses\"], axis=1)\n",
        "def_data[\"shortcode\"] = def_data[\"shortcode\"].apply(str)\n",
        "def_data[\"unicode\"] = def_data[\"unicode\"].apply(str)\n",
        "def_data = def_data.loc[def_data[\"shortcode\"] != \"None\"]\n",
        "\n",
        "def_data[\"unicode\"].index\n",
        "for i,code in zip(def_data[\"unicode\"].index,def_data[\"unicode\"]):\n",
        "  if len(code.split()) == 1:\n",
        "    def_data[\"unicode\"][i] = make_uchr(code)\n",
        "#print(def_data[\"unicode\"].values)\n",
        "def_data"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>keywords</th>\n",
              "      <th>definition</th>\n",
              "      <th>unicode</th>\n",
              "      <th>shortcode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[keycap]</td>\n",
              "      <td>Keycap Digit Zero was approved as part of Unic...</td>\n",
              "      <td>U+0030 U+FE0F U+20E3</td>\n",
              "      <td>:zero:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>[m, circle]</td>\n",
              "      <td>The letter M in a circle, commonly used in to ...</td>\n",
              "      <td>Ⓜ</td>\n",
              "      <td>:m:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>[japanese, ?, “acceptable”, ideograph]</td>\n",
              "      <td>Japanese “acceptable” Button was approved as p...</td>\n",
              "      <td>🉑</td>\n",
              "      <td>:accept:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>[japanese, ?, “bargain”, ideograph]</td>\n",
              "      <td>Denotes a “good bargain” in Japanese. Japanese...</td>\n",
              "      <td>🉐</td>\n",
              "      <td>:ideograph_advantage:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>[japanese, ?, “open for business”, ideograph]</td>\n",
              "      <td>Means “work” in Japanese.  This Emoji used to ...</td>\n",
              "      <td>🈺</td>\n",
              "      <td>:u55b6:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2383</th>\n",
              "      <td>[sun, mountain, sunrise, morning]</td>\n",
              "      <td>The sun rising over a mountain range, early in...</td>\n",
              "      <td>🌄</td>\n",
              "      <td>:sunrise_over_mountains:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2384</th>\n",
              "      <td>[night, star]</td>\n",
              "      <td>A night sky with stars, depicted on major plat...</td>\n",
              "      <td>🌃</td>\n",
              "      <td>:night_with_stars:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2385</th>\n",
              "      <td>[umbrella, rain, clothing]</td>\n",
              "      <td>An umbrella that is closed, likely as a result...</td>\n",
              "      <td>🌂</td>\n",
              "      <td>:closed_umbrella:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2386</th>\n",
              "      <td>[fog]</td>\n",
              "      <td>Foggy weather emoji. Shows fog covering a view...</td>\n",
              "      <td>🌁</td>\n",
              "      <td>:foggy:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2387</th>\n",
              "      <td>[typhoon, dizzy, twister]</td>\n",
              "      <td>An icon used to represent a cyclone. Some vers...</td>\n",
              "      <td>🌀</td>\n",
              "      <td>:cyclone:</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>845 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           keywords  ...                 shortcode\n",
              "5                                          [keycap]  ...                    :zero:\n",
              "140                                     [m, circle]  ...                       :m:\n",
              "196          [japanese, ?, “acceptable”, ideograph]  ...                  :accept:\n",
              "197             [japanese, ?, “bargain”, ideograph]  ...     :ideograph_advantage:\n",
              "201   [japanese, ?, “open for business”, ideograph]  ...                   :u55b6:\n",
              "...                                             ...  ...                       ...\n",
              "2383              [sun, mountain, sunrise, morning]  ...  :sunrise_over_mountains:\n",
              "2384                                  [night, star]  ...        :night_with_stars:\n",
              "2385                     [umbrella, rain, clothing]  ...         :closed_umbrella:\n",
              "2386                                          [fog]  ...                   :foggy:\n",
              "2387                      [typhoon, dizzy, twister]  ...                 :cyclone:\n",
              "\n",
              "[845 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh6JwZQnoRUi"
      },
      "source": [
        "def_data.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2grJIsKbopLx",
        "outputId": "bc9b2f47-0a1f-46e5-9126-e09d2cbdaac3"
      },
      "source": [
        "def_data.iloc[0]"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "keywords                                               [keycap]\n",
              "definition    Keycap Digit Zero was approved as part of Unic...\n",
              "unicode                                    U+0030 U+FE0F U+20E3\n",
              "shortcode                                                :zero:\n",
              "Name: 5, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CkoC_DQnHlJ"
      },
      "source": [
        "MC_20 = ['❤','😂', '👍', '🙏', '🙌', '😘', '😍', '😊', '🔥', '👏', '👌', '💪', '👊', '😉', '🎉', '😎',\"😁\", \"💯\", \"😜\", \"👀\"]\n",
        "eval = pd.DataFrame([def_data.iloc[i,] for i in range(len(def_data[\"unicode\"])) if def_data.iloc[i,][\"unicode\"] in MC_20 ])"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "QGABXHIMo32k",
        "outputId": "4299ed6b-e32c-410d-8138-6e5acb2307b3"
      },
      "source": [
        "eval.columns = [\"key\", \"Line\", \"Emoji\", \"sc\"]\n",
        "eval"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>key</th>\n",
              "      <th>Line</th>\n",
              "      <th>Emoji</th>\n",
              "      <th>sc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>893</th>\n",
              "      <td>[hand, gesture, pray, bow, please, thanks, fol...</td>\n",
              "      <td>Two hands placed firmly together, meaning plea...</td>\n",
              "      <td>🙏</td>\n",
              "      <td>:pray:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897</th>\n",
              "      <td>[hooray, hand, gesture, raised, celebration]</td>\n",
              "      <td>Two hands raised in the air, celebrating succe...</td>\n",
              "      <td>🙌</td>\n",
              "      <td>:raised_hands:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>962</th>\n",
              "      <td>[eye, wink, face, tongue, joke]</td>\n",
              "      <td>A face showing a stuck-out tongue, winking at ...</td>\n",
              "      <td>😜</td>\n",
              "      <td>:stuck_out_tongue_winking_eye:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>967</th>\n",
              "      <td>[kiss, face]</td>\n",
              "      <td>An emoji face blowing a kiss; but officially c...</td>\n",
              "      <td>😘</td>\n",
              "      <td>:kissing_heart:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>977</th>\n",
              "      <td>[eyewear, smile, eye, sun, glasses, sunglasses...</td>\n",
              "      <td>A face smiling and wearing dark sunglasses tha...</td>\n",
              "      <td>😎</td>\n",
              "      <td>:sunglasses:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>979</th>\n",
              "      <td>[eye, smile, love, face]</td>\n",
              "      <td>A face with hearts instead of eyes, or Heart E...</td>\n",
              "      <td>😍</td>\n",
              "      <td>:heart_eyes:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>982</th>\n",
              "      <td>[eye, smile, face, blush]</td>\n",
              "      <td>A smiling face, with smiling eyes and rosy che...</td>\n",
              "      <td>😊</td>\n",
              "      <td>:blush:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>983</th>\n",
              "      <td>[wink, face]</td>\n",
              "      <td>A classic winky emoji; winking and smiling. Us...</td>\n",
              "      <td>😉</td>\n",
              "      <td>:wink:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991</th>\n",
              "      <td>[laugh, joy, face, tear]</td>\n",
              "      <td>A laughing emoji which at small sizes is often...</td>\n",
              "      <td>😂</td>\n",
              "      <td>:joy:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>992</th>\n",
              "      <td>[eye, smile, grin, face]</td>\n",
              "      <td>A version of the grinning face showing smiling...</td>\n",
              "      <td>😁</td>\n",
              "      <td>:grin:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1268</th>\n",
              "      <td>[heart]</td>\n",
              "      <td>A classic red love heart emoji, used to expres...</td>\n",
              "      <td>❤</td>\n",
              "      <td>:heart:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1289</th>\n",
              "      <td>[tool, flame]</td>\n",
              "      <td>A small flame, mostly yellow but red at the to...</td>\n",
              "      <td>🔥</td>\n",
              "      <td>:fire:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1571</th>\n",
              "      <td>[full, 100, hundred, score]</td>\n",
              "      <td>100 emoji: the number one-hundred, written in ...</td>\n",
              "      <td>💯</td>\n",
              "      <td>:100:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1579</th>\n",
              "      <td>[muscle, comic, flex, biceps]</td>\n",
              "      <td>An arm flexing to show its biceps muscle. Repr...</td>\n",
              "      <td>💪</td>\n",
              "      <td>:muscle:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1791</th>\n",
              "      <td>[clap, hand]</td>\n",
              "      <td>Two hands clapping emoji, which when used mult...</td>\n",
              "      <td>👏</td>\n",
              "      <td>:clap:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1793</th>\n",
              "      <td>[up, thumb, hand, +1]</td>\n",
              "      <td>A thumbs-up gesture indicating approval. Thumb...</td>\n",
              "      <td>👍</td>\n",
              "      <td>:+1:,:thumbsup:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1794</th>\n",
              "      <td>[hand, ok]</td>\n",
              "      <td>Index finger touching thumb to make an open ci...</td>\n",
              "      <td>👌</td>\n",
              "      <td>:ok_hand:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1797</th>\n",
              "      <td>[hand, fist, punch, clenched]</td>\n",
              "      <td>A fist displayed in a position to punch someon...</td>\n",
              "      <td>👊</td>\n",
              "      <td>:facepunch:,:punch:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1817</th>\n",
              "      <td>[eye, face]</td>\n",
              "      <td>A pair of eyes, glancing slightly to the left ...</td>\n",
              "      <td>👀</td>\n",
              "      <td>:eyes:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2195</th>\n",
              "      <td>[popper, party, tada, celebration]</td>\n",
              "      <td>A colorful party popper, used for party or oth...</td>\n",
              "      <td>🎉</td>\n",
              "      <td>:tada:</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    key  ...                              sc\n",
              "893   [hand, gesture, pray, bow, please, thanks, fol...  ...                          :pray:\n",
              "897        [hooray, hand, gesture, raised, celebration]  ...                  :raised_hands:\n",
              "962                     [eye, wink, face, tongue, joke]  ...  :stuck_out_tongue_winking_eye:\n",
              "967                                        [kiss, face]  ...                 :kissing_heart:\n",
              "977   [eyewear, smile, eye, sun, glasses, sunglasses...  ...                    :sunglasses:\n",
              "979                            [eye, smile, love, face]  ...                    :heart_eyes:\n",
              "982                           [eye, smile, face, blush]  ...                         :blush:\n",
              "983                                        [wink, face]  ...                          :wink:\n",
              "991                            [laugh, joy, face, tear]  ...                           :joy:\n",
              "992                            [eye, smile, grin, face]  ...                          :grin:\n",
              "1268                                            [heart]  ...                         :heart:\n",
              "1289                                      [tool, flame]  ...                          :fire:\n",
              "1571                        [full, 100, hundred, score]  ...                           :100:\n",
              "1579                      [muscle, comic, flex, biceps]  ...                        :muscle:\n",
              "1791                                       [clap, hand]  ...                          :clap:\n",
              "1793                              [up, thumb, hand, +1]  ...                 :+1:,:thumbsup:\n",
              "1794                                         [hand, ok]  ...                       :ok_hand:\n",
              "1797                      [hand, fist, punch, clenched]  ...             :facepunch:,:punch:\n",
              "1817                                        [eye, face]  ...                          :eyes:\n",
              "2195                 [popper, party, tada, celebration]  ...                          :tada:\n",
              "\n",
              "[20 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7_o-eY4DyEd"
      },
      "source": [
        "# Data preps. for Twitter\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvkLqTLmx5c0",
        "outputId": "4e42fce5-c483-48f0-df6c-032ea5bc9d7d"
      },
      "source": [
        "meta = pd.read_csv(\"/content/drive/My Drive/NLP/Data/meta/metadata.txt\",sep=\"\\t\")\n",
        "meta\n",
        "folds = meta.loc[0:20,]\n",
        "folds \n",
        "MC_20 = ['❤','😂', '👍', '🙏', '🙌', '😘', '😍', '😊', '🔥', '👏', '👌', '💪', '👊', '😉', '🎉', '😎',\"😁\", \"💯\", \"😜\", \"👀\"]\n",
        "folds = pd.DataFrame([meta.loc[i,] for i in range(len(meta[\" emoji \"])) if meta.loc[i,][\" emoji \"] in MC_20 ])\n",
        "sum(folds[\" len \"])"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "308616"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGJemSPnmo6e",
        "outputId": "b6f18ca6-f359-4a07-9c62-9e478df96e4a"
      },
      "source": [
        "labs = {}\n",
        "for i,fold in enumerate(folds[\" emoji \"]):\n",
        "  labs[fold]=i\n",
        "labs"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'❤': 4,\n",
              " '🎉': 11,\n",
              " '👀': 16,\n",
              " '👊': 1,\n",
              " '👌': 13,\n",
              " '👍': 15,\n",
              " '👏': 6,\n",
              " '💪': 0,\n",
              " '💯': 12,\n",
              " '🔥': 7,\n",
              " '😁': 9,\n",
              " '😂': 19,\n",
              " '😉': 10,\n",
              " '😊': 17,\n",
              " '😍': 18,\n",
              " '😎': 8,\n",
              " '😘': 14,\n",
              " '😜': 5,\n",
              " '🙌': 2,\n",
              " '🙏': 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 245
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9xqmeQyZRXh"
      },
      "source": [
        "dataa = {}\n",
        "\n",
        "for i,fold in enumerate(folds[\"index \"]):\n",
        "  p = pd.read_csv(\"/content/drive/My Drive/NLP/Data\" +\"/\"+ str(fold)+\".csv\")\n",
        "  perc = np.random.rand(p.shape[0])\n",
        "  perc = perc > 0.9\n",
        "  p[\"test\"] = perc\n",
        "  dataa[i] = p"
      ],
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "52oTV0XZAdRS",
        "outputId": "b2fe449f-d06a-4b0d-bbf0-d41286a52228"
      },
      "source": [
        "dataa[5]"
      ],
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Line</th>\n",
              "      <th>Emoji</th>\n",
              "      <th>test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>327</td>\n",
              "      <td>john barrowman should never be allowed to forg...</td>\n",
              "      <td>😜</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>348</td>\n",
              "      <td>i been let that hurt go idc no more</td>\n",
              "      <td>😜</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>458</td>\n",
              "      <td>follow spreeeee fashion photograph music marve...</td>\n",
              "      <td>😜</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>517</td>\n",
              "      <td>i'm not sure we want to find out</td>\n",
              "      <td>😜</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>523</td>\n",
              "      <td>yellin on waianaes side wearing a saint louis ...</td>\n",
              "      <td>😜</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5058</th>\n",
              "      <td>928004</td>\n",
              "      <td>should of came to dunkin</td>\n",
              "      <td>😜</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5059</th>\n",
              "      <td>928201</td>\n",
              "      <td>it was a jab at muslims ham</td>\n",
              "      <td>😜</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5060</th>\n",
              "      <td>928416</td>\n",
              "      <td>waiting for election results be like</td>\n",
              "      <td>😜</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5061</th>\n",
              "      <td>928432</td>\n",
              "      <td>i've gotten tamra a few times</td>\n",
              "      <td>😜</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5062</th>\n",
              "      <td>928834</td>\n",
              "      <td>oooh i like this but i also like nutella sandw...</td>\n",
              "      <td>😜</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5063 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  ...   test\n",
              "0            327  ...   True\n",
              "1            348  ...  False\n",
              "2            458  ...  False\n",
              "3            517  ...  False\n",
              "4            523  ...  False\n",
              "...          ...  ...    ...\n",
              "5058      928004  ...  False\n",
              "5059      928201  ...  False\n",
              "5060      928416  ...   True\n",
              "5061      928432  ...   True\n",
              "5062      928834  ...  False\n",
              "\n",
              "[5063 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYEcwVlHD2Jv"
      },
      "source": [
        "# Data preps for MC20\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csHzpfEc3zXw"
      },
      "source": [
        "MC_20 = ['❤','😂', '👍', '🙏', '🙌', '😘', '😍', '😊', '🔥', '👏', '👌', '💪', '👊', '😉', '🎉', '😎',\"😁\", \"💯\", \"😜\", \"👀\"]\n",
        "data_path = '/content/drive/MyDrive/NLP/NLP project/datasets/MC_20_dev.csv'\n",
        "\n",
        "data_set = pd.read_csv(data_path)\n",
        "data_set.columns = ['Line', 'Emoji']\n",
        " # take 10000 i.e \n",
        "#data_set.loc[data_set['lable']=='😂']\n"
      ],
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJMjJv4c5ek8",
        "outputId": "24bdf859-005e-49ad-ebe0-fd860219bdf6"
      },
      "source": [
        "dataa = {}\n",
        "\n",
        "for i,lab in enumerate(MC_20):\n",
        "  p = data_set.loc[data_set['Emoji']== lab]\n",
        "  perc = np.random.rand(p.shape[0])\n",
        "  perc = perc > 0.9\n",
        "  p[\"test\"] = perc\n",
        "  dataa[i] = p"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "nj6viC0W6Dy8",
        "outputId": "102198d7-5d91-4bbe-cf47-d3b7d8e910c7"
      },
      "source": [
        "dataa[16]"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Line</th>\n",
              "      <th>Emoji</th>\n",
              "      <th>test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>@benmckenna @SkyNews Thanks Ben. Yes. *#*^+ #=...</td>\n",
              "      <td>😁</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>आजकल '2000 के नोट में चिप लगी है जिससे इनकम टै...</td>\n",
              "      <td>😁</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>“@Ciinnnddddyyyy: @mgracex0  can you PLEASE tw...</td>\n",
              "      <td>😁</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>This how 24 feel  https://t.co/D8EY7VKCXC</td>\n",
              "      <td>😁</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>RT @dbirdw: @FrankWaln Can’t wait</td>\n",
              "      <td>😁</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399813</th>\n",
              "      <td>Selection Sunday</td>\n",
              "      <td>😁</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399838</th>\n",
              "      <td>Lost to fluminense, but the boys dug deep to b...</td>\n",
              "      <td>😁</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399862</th>\n",
              "      <td>“@boytroublez: @MrSuPeRsTar_30 ️ I still love ...</td>\n",
              "      <td>😁</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399902</th>\n",
              "      <td>RT @pittman_nairobi: @BurtonABC7 @ABC7Chicago ...</td>\n",
              "      <td>😁</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399928</th>\n",
              "      <td>Am looking forward to haven you back Monday , ...</td>\n",
              "      <td>😁</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19060 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     Line Emoji   test\n",
              "5       @benmckenna @SkyNews Thanks Ben. Yes. *#*^+ #=...     😁  False\n",
              "7       आजकल '2000 के नोट में चिप लगी है जिससे इनकम टै...     😁  False\n",
              "13      “@Ciinnnddddyyyy: @mgracex0  can you PLEASE tw...     😁  False\n",
              "68              This how 24 feel  https://t.co/D8EY7VKCXC     😁  False\n",
              "73                     RT @dbirdw: @FrankWaln Can’t wait      😁  False\n",
              "...                                                   ...   ...    ...\n",
              "399813                                  Selection Sunday      😁  False\n",
              "399838  Lost to fluminense, but the boys dug deep to b...     😁  False\n",
              "399862  “@boytroublez: @MrSuPeRsTar_30 ️ I still love ...     😁  False\n",
              "399902  RT @pittman_nairobi: @BurtonABC7 @ABC7Chicago ...     😁  False\n",
              "399928  Am looking forward to haven you back Monday , ...     😁  False\n",
              "\n",
              "[19060 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tj6GNNTm4f5r",
        "outputId": "4ccf8ac9-67bd-4153-f98f-6ffd835eb2e0"
      },
      "source": [
        "import re\n",
        "test = dataa[0][\"Line\"][6]\n",
        "print(test)\n",
        "s = re.sub(r'http\\S+', '', test)\n",
        "s = re.sub(r'@\\S+', '', s)\n",
        "s = re.sub(r'[^\\w\\s]','',s)\n",
        "s = re.sub(r'\\w+_\\S+',\"\", s)\n",
        "print(s)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RT @SarahKSilverman:  but also ️️️️️️️️ https://t.co/kK1TbVlx4D\n",
            "RT   but also  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzM9z0u9t22O"
      },
      "source": [
        "## BERT himself"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EfPzA8Hm-0Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165,
          "referenced_widgets": [
            "2c4e9e26d8754495b5b9f8c899b73576",
            "d6d6e91623a64527a97a3be80e15e93b",
            "5c591b1556c7461cbc0531fae0daff0a",
            "9fabd0e9e4e84155b5054ff53641cd39",
            "c9067d92e1924a359d28b84bc45ab302",
            "bc310820b9b14d2b81e1e3b8a4d14be4",
            "f420bdef198d48f4b0053c6e3adeefb5",
            "a36afb25d30d4e0ba11968c4327bffc0",
            "c832d0f1f8094f9289c89b147f04289b",
            "b3a454c12d4f451191fcbf787a57dad8",
            "610b6e23d680404da2272ecf11daabd6",
            "20548c57241443859bd6e408e7c497da",
            "dab2d9b73e4440b0ba428e757cd5ead1",
            "747ab219467b47ba9bb7381c8bf08685",
            "d03d3541c4e64133a795d99a8f89ac6a",
            "267b2070c1d54261a0877ecbb5103fa6",
            "ae6e17b3191c45ec8d332e5944416387",
            "7dd3611e1834457a9118f4b1b4691195",
            "8d844d67ce0d4221bf0f0d0d82feb67a",
            "76e23b8122034d71a559b1a15b1ab481",
            "96dc99cea03c43df8c428351e6ccf218",
            "47149a8fdd0842d98f9c0dc69e6fa6bf",
            "dd4f9b9bfae04b858d2aff987f8b8d81",
            "6b88623741d945e89531faf75b3cb061"
          ]
        },
        "outputId": "6cdf5b15-ade6-4972-85f6-d74018a15336"
      },
      "source": [
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\", do_lower_case=True, padding_side=\"right\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c4e9e26d8754495b5b9f8c899b73576",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c832d0f1f8094f9289c89b147f04289b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae6e17b3191c45ec8d332e5944416387",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIK-URPGncKv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fa50677-6eb9-433f-e66b-1943e97d01ab"
      },
      "source": [
        "print(tokenizer.tokenize(\"This is the BERT tokenizer that we're going to use today.\"))\n",
        "print(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"This is the BERT tokenizer that we're going to use today.\")))\n",
        "tokenizer.encode_plus(\"This is the BERT tokenizer that we're going to use today.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['this', 'is', 'the', 'bert', 'token', '##izer', 'that', 'we', \"'\", 're', 'going', 'to', 'use', 'today', '.']\n",
            "[2023, 2003, 1996, 14324, 19204, 17629, 2008, 2057, 1005, 2128, 2183, 2000, 2224, 2651, 1012]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 2023, 2003, 1996, 14324, 19204, 17629, 2008, 2057, 1005, 2128, 2183, 2000, 2224, 2651, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXQiZKhtns-p"
      },
      "source": [
        "PAD = '[PAD]'\n",
        "PAD_ID = 0\n",
        "DATA_PATH = Path('data') / 'aclImdb'\n",
        "\n",
        "batch_size = 16\n",
        "validation_split = .1\n",
        "shuffle_dataset = True\n",
        "random_seed = 42"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl11K6H4FmVT"
      },
      "source": [
        "Last modification that we make is adding `attention_masks`. This vector is basically telling the model which characters are meaningful and which one are used for padding. To do that, we put `1` in the position of meaningful tokens and `0` in the position of paddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj1Dyq9NoOQq"
      },
      "source": [
        "class EmojiDataSet(Dataset):\n",
        "    def __init__(self, folders, pretrain_tokenizer, data, test=False):\n",
        "        self.tokenizer = pretrain_tokenizer\n",
        "        self.label_vocab = folders\n",
        "        self.max_len = 128\n",
        "        self.sign = False\n",
        "        self.in_data= data\n",
        "\n",
        "        if test:\n",
        "            self.sign = True\n",
        "        else:\n",
        "            self.sign = False\n",
        "            \n",
        "        self.data = []\n",
        "        \n",
        "        self.load()\n",
        "        \n",
        "    def load(self):\n",
        "        for label in self.label_vocab:\n",
        "          p = self.in_data[self.label_vocab[label]].dropna()\n",
        "          p = p.loc[p[\"test\"]==self.sign]\n",
        "          perc2 = np.random.rand(p.shape[0])\n",
        "          perc2 = perc2 < 0.66 # for twitter\n",
        "          #perc2 = perc2 < 0.5 # for MC20\n",
        "          p[\"inc\"] = perc2\n",
        "          p = p.loc[p[\"inc\"]==True]\n",
        "          print(f'Reading {label} sentences...')\n",
        "          for line in p[\"Line\"]:\n",
        "            #s = re.sub(r'http\\S+', '', line)# only for MC20\n",
        "            #s = re.sub(r'@\\S+', '', s)# only for MC20\n",
        "            #s = re.sub(r'[^\\w\\s]','',s)# only for MC20\n",
        "            #line = re.sub(r'\\w+_\\S+',\"\", s)# only for MC20\n",
        "            text = self.tokenizer.encode(line, add_special_tokens = True, max_length=self.max_len, padding= \"max_length\", truncation = True, return_tensors = \"pt\")\n",
        "            attention_mask = text > 0\n",
        "            attention_mask = attention_mask.squeeze()\n",
        "            torch_label = torch.tensor(self.label_vocab[label], dtype = torch.long)\n",
        "              # append text, attention text and torch_label\n",
        "            self.data.append((text.squeeze(), attention_mask, torch_label))\n",
        "                \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx][0], self.data[idx][1], self.data[idx][2]"
      ],
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFM42wwFpCVx"
      },
      "source": [
        "train_data = EmojiDataSet(folders = labs,pretrain_tokenizer=tokenizer, data=dataa)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8h9KRWppIzM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcecb896-8cbb-4f23-a549-f654ce3e18a6"
      },
      "source": [
        "test_data = EmojiDataSet(folders = labs,pretrain_tokenizer=tokenizer, data=dataa, test=True)"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading 💪 sentences...\n",
            "Reading 👊 sentences...\n",
            "Reading 🙌 sentences...\n",
            "Reading 🙏 sentences...\n",
            "Reading ❤ sentences...\n",
            "Reading 😜 sentences...\n",
            "Reading 👏 sentences...\n",
            "Reading 🔥 sentences...\n",
            "Reading 😎 sentences...\n",
            "Reading 😁 sentences...\n",
            "Reading 😉 sentences...\n",
            "Reading 🎉 sentences...\n",
            "Reading 💯 sentences...\n",
            "Reading 👌 sentences...\n",
            "Reading 😘 sentences...\n",
            "Reading 👍 sentences...\n",
            "Reading 👀 sentences...\n",
            "Reading 😊 sentences...\n",
            "Reading 😍 sentences...\n",
            "Reading 😂 sentences...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzmR3s2IpqqD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f935ea3e-0005-4b39-bd4b-951d4a85345f"
      },
      "source": [
        "len(test_data)"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20621"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqczduULq4OV"
      },
      "source": [
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(train_data)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "if shuffle_dataset:\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As_arcISsOzj"
      },
      "source": [
        "#train_loader = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\n",
        "#validation_loader = DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size)"
      ],
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-Eae5oXsUak",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "fd130b751e99427a94ea2cb200b1345e",
            "97780080c045416bb10388f8bcb78053",
            "833acc0d13344263be068a9c7214a2ed",
            "6f9613b9dd144a65a73109f707f4e197",
            "94bbb9af17394e2b935d17e81838f444",
            "fc98a6276f7d4c00a911adc510e67df9",
            "638ff42ad4284cbca74a2c93759f610b",
            "119532ca96af403a8e71fb5922ca3cf5",
            "fa2800ef078a4e2a84d3d9062f47da10",
            "e7836dc15c364084bbf635f7f3adee7a",
            "002d07f0eb064d3faaa4ea7f863dc969",
            "9dd08423806a48c0b22ad731113e30bd",
            "7c5eaf4fc1824b5a9bd6eccd8be9b30c",
            "9bdcdee77681492e95033d7894a400a2",
            "a2858b3aaa6a4136a52b1dd3e57362fa",
            "28463dc7ea46415c8afa976b194ae9fc"
          ]
        },
        "outputId": "88d4b6b7-4bc0-4d75-cb1f-ee2030d6e59c"
      },
      "source": [
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels= len(train_data.label_vocab), output_attentions = False, output_hidden_states=False)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd130b751e99427a94ea2cb200b1345e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa2800ef078a4e2a84d3d9062f47da10",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267967963.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (1): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (2): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (3): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (4): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (5): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=20, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGhKQ6jsswJA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb4078cd-abe7-4db6-d4f4-f781161c9fac"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The DistilBERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The DistilBERT model has 104 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "distilbert.embeddings.word_embeddings.weight            (30522, 768)\n",
            "distilbert.embeddings.position_embeddings.weight          (512, 768)\n",
            "distilbert.embeddings.LayerNorm.weight                        (768,)\n",
            "distilbert.embeddings.LayerNorm.bias                          (768,)\n",
            "distilbert.transformer.layer.0.attention.q_lin.weight     (768, 768)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "distilbert.transformer.layer.0.attention.q_lin.bias           (768,)\n",
            "distilbert.transformer.layer.0.attention.k_lin.weight     (768, 768)\n",
            "distilbert.transformer.layer.0.attention.k_lin.bias           (768,)\n",
            "distilbert.transformer.layer.0.attention.v_lin.weight     (768, 768)\n",
            "distilbert.transformer.layer.0.attention.v_lin.bias           (768,)\n",
            "distilbert.transformer.layer.0.attention.out_lin.weight   (768, 768)\n",
            "distilbert.transformer.layer.0.attention.out_lin.bias         (768,)\n",
            "distilbert.transformer.layer.0.sa_layer_norm.weight           (768,)\n",
            "distilbert.transformer.layer.0.sa_layer_norm.bias             (768,)\n",
            "distilbert.transformer.layer.0.ffn.lin1.weight           (3072, 768)\n",
            "distilbert.transformer.layer.0.ffn.lin1.bias                 (3072,)\n",
            "distilbert.transformer.layer.0.ffn.lin2.weight           (768, 3072)\n",
            "distilbert.transformer.layer.0.ffn.lin2.bias                  (768,)\n",
            "distilbert.transformer.layer.0.output_layer_norm.weight       (768,)\n",
            "distilbert.transformer.layer.0.output_layer_norm.bias         (768,)\n",
            "distilbert.transformer.layer.1.attention.q_lin.weight     (768, 768)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "pre_classifier.weight                                     (768, 768)\n",
            "pre_classifier.bias                                           (768,)\n",
            "classifier.weight                                          (20, 768)\n",
            "classifier.bias                                                (20,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5gyvqU9s-ze"
      },
      "source": [
        "lrs = [5e-5, 4e-5, 3e-5, 2e-5]\n",
        "optimizer = AdamW(model.parameters(), lr = lrs[0], eps = 1e-8)\n",
        "\n",
        "batch_sizes = [16,32]\n",
        "batch_size = 16\n",
        "epochs = 3\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_loader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 5000,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUzffNJ3uMcF"
      },
      "source": [
        "## Measures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClW0hk8ZtgQ4"
      },
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1elhoy6vDrP"
      },
      "source": [
        "def MRR(preds, labels, labs):\n",
        "  n = len(labs)\n",
        "  ranks = np.argsort(preds.T, axis=0)[-n:][::-1]\n",
        "  x = np.tile(labels, (n, 1))\n",
        "  #print(preds, x, ranks)\n",
        "  return np.sum(np.sum(ranks == x, axis=1)*(1/(np.arange(n)+1)))/len(labels)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBXToE2qrJWS"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "def multi_label_accuracy(preds, y):\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = np.argmax(preds, axis=1).flatten()\n",
        "    #print(rounded_preds, y)\n",
        "    #precision, recall, f_score, n = precision_recall_fscore_support(y, rounded_preds,labels = np.arange(20), average=None) # macro\n",
        "    #precision, recall, f_score, n = precision_recall_fscore_support(y, rounded_preds, average=\"macro\") # macro\n",
        "    \n",
        "    #confusion_vector = rounded_preds / y\n",
        "    \n",
        "    #true_positives = np.sum(confusion_vector == 1)\n",
        "    #false_positives = np.sum(np.isinf(confusion_vector))\n",
        "    #false_negatives = np.sum(confusion_vector == 0)\n",
        "    #true_negatives = np.sum(np.isnan(confusion_vector))\n",
        "\n",
        "    accuracy = (np.sum(rounded_preds == y)) / (len(y))\n",
        "    #precision = (true_positives) / (true_positives+false_positives)\n",
        "    #recall = (true_positives) / (true_positives+false_negatives)\n",
        "    #f_score = 2*(precision*recall)/(precision+recall)\n",
        "    #return accuracy, precision, recall, f_score, n\n",
        "    return accuracy, rounded_preds, y"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5G9QWPUtpcF"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7X3HT-ouOlh"
      },
      "source": [
        "## Training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfUd-Wr3t7rO"
      },
      "source": [
        "# Taken from this tutorial: https://github.com/aniruddhachoudhury/BERT-Tutorials/blob/master/Blog%202/BERT_Fine_Tuning_Sentence_Classification.ipynb\n",
        "# The code was modified\n",
        "\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed_all(random_seed)\n",
        "\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_loader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed_mins, elapsed_secs = epoch_time(t0, time.time())\n",
        "            \n",
        "            # Report progress.\n",
        "            print(f'  Batch {step:>5,}  of  {len(train_loader):>5,}.    Elapsed: {elapsed_mins:}m {elapsed_secs:}s.')\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/model_doc/distilbert.html#distilbertforsequenceclassification\n",
        "        outputs = model(b_input_ids, attention_mask= b_input_mask, labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_loader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(f\"  Average training loss: {avg_train_loss:.4f}\")\n",
        "    print(\"  Training epcoh took: {:}m {:}s\".format(*epoch_time(t0, time.time())))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy, eval_pre, eval_rec, eval_f1 = 0, 0, 0, 0, 0\n",
        "    mrr_eval = 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_loader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/model_doc/distilbert.html#distilbertforsequenceclassification\n",
        "            outputs = model(b_input_ids, attention_mask= b_input_mask)\n",
        "\n",
        "\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "        \n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to(\"cpu\").numpy()\n",
        "        #print(label_ids)\n",
        "        #print( np.argmax(logits, axis=1).flatten())\n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = multi_label_accuracy(logits, label_ids)\n",
        "        #tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        tmp_eval_mrr = MRR(logits, label_ids, labs)\n",
        "        # Accumulate the total accuracy.\n",
        "        #eval_accuracy += tmp_eval_accuracy\n",
        "        eval_accuracy += tmp_eval_accuracy[0]\n",
        "        eval_pre += tmp_eval_accuracy[1]\n",
        "        eval_rec += tmp_eval_accuracy[2]\n",
        "        eval_f1 += tmp_eval_accuracy[3]\n",
        "        mrr_eval += tmp_eval_mrr\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.6f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Precision: {0:.2f}\".format(eval_pre/nb_eval_steps))\n",
        "    print(\"  Recall: {0:.2f}\".format(eval_rec/nb_eval_steps))\n",
        "    print(\"  F1_score: {0:.2f}\".format(eval_f1/nb_eval_steps))\n",
        "    print(\"  MRR_score: {0:.3f}\".format(mrr_eval/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}m {:}s\".format(*epoch_time(t0, time.time())))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f33nbvQ1v2A6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "1e0e6728-c2a5-425d-9e74-2031f57838c4"
      },
      "source": [
        "\n",
        "print(\"\")\n",
        "print(\"Running Testing...\")\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# Put the model in evaluation mode--the dropout layers behave differently\n",
        "# during evaluation.\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "test_loss = 0\n",
        "test_accuracy, test_pre, test_rec, test_f1 = np.zeros(20),np.zeros(20),np.zeros(20),np.zeros(20)\n",
        "counter_y = []\n",
        "counter_pred = []\n",
        "test_mrr = 0\n",
        "nb_test_steps, nb_test_examples = 0, 0\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for batch in test_loader:\n",
        "    \n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # Telling the model not to compute or store gradients, saving memory and\n",
        "    # speeding up validation\n",
        "    with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        # This will return the logits rather than the loss because we have\n",
        "        # not provided labels.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/model_doc/distilbert.html#distilbertforsequenceclassification\n",
        "        outputs = model(b_input_ids, b_input_mask)\n",
        "\n",
        "\n",
        "    # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "    # values prior to applying an activation function like the softmax.\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to(\"cpu\").numpy()\n",
        "    #print(label_ids)\n",
        "    #print( np.argmax(logits, axis=1).flatten())\n",
        "    # Calculate the accuracy for this batch of test sentences.\n",
        "    #tmp_test_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "    tmp_test_accuracy = multi_label_accuracy(logits, label_ids)\n",
        "    tmp_eval_mrr = MRR(logits, label_ids, labs)\n",
        "    # Accumulate the total accuracy.\n",
        "    #print(tmp_test_accuracy)\n",
        "    test_accuracy += tmp_test_accuracy[0]\n",
        "    #test_pre += tmp_test_accuracy[1]\n",
        "    #test_rec += tmp_test_accuracy[2]\n",
        "    #test_f1 += tmp_test_accuracy[3]\n",
        "    test_mrr += tmp_eval_mrr\n",
        "    counter_y += tmp_test_accuracy[2].tolist()\n",
        "\n",
        "    counter_pred += tmp_test_accuracy[1].tolist()\n",
        "    #print(tmp_test_accuracy)\n",
        "    # Track the number of batches\n",
        "    nb_test_steps += 1\n",
        "\n",
        "# Report the final accuracy for this test run.\n",
        "print(\"  Accuracy: {0:.2f}\".format(test_accuracy/nb_test_steps))\n",
        "print(\"  Precision: {0:.2f}\".format(test_pre/nb_test_steps))\n",
        "print(\"  Recall: {0:.2f}\".format(test_rec/nb_test_steps))\n",
        "print(\"  F1_score: {0:.2f}\".format(test_f1/nb_test_steps))\n",
        "print(\"  MRR_score: {0:.3f}\".format(test_mrr/nb_test_steps))\n",
        "print(\"  Testing took: {:}m {:}s\".format(*epoch_time(t0, time.time())))"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Running Testing...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-252-24730d594f51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m# Report the final accuracy for this test run.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  Accuracy: {0:.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_accuracy\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnb_test_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  Precision: {0:.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_pre\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnb_test_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  Recall: {0:.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_rec\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnb_test_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to numpy.ndarray.__format__"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KX4NSYR1Noi",
        "outputId": "030a3f8c-318a-4114-bde6-cdac0bfbc706"
      },
      "source": [
        "test_mrr/nb_test_steps"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6886797328170433"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YtG4vNLlkFM",
        "outputId": "ffc96da0-dbf5-43bd-d186-5bc33bef251b"
      },
      "source": [
        "precision, recall, f_score, n = precision_recall_fscore_support(counter_y, counter_pred,labels = np.arange(20), average=None)"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPClmbxEvRHa",
        "outputId": "1cac428a-892f-4f97-d89f-3caac8537400"
      },
      "source": [
        "print(sum(np.array(counter_pred) == np.array(counter_y))/len(counter_y))"
      ],
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5647640754570583\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsI9w5uB2832",
        "outputId": "1dfe8c99-aaf5-4454-89c0-91082e25fc98"
      },
      "source": [
        "inv_voc"
      ],
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '💪',\n",
              " 1: '👊',\n",
              " 2: '🙌',\n",
              " 3: '🙏',\n",
              " 4: '❤',\n",
              " 5: '😜',\n",
              " 6: '👏',\n",
              " 7: '🔥',\n",
              " 8: '😎',\n",
              " 9: '😁',\n",
              " 10: '😉',\n",
              " 11: '🎉',\n",
              " 12: '💯',\n",
              " 13: '👌',\n",
              " 14: '😘',\n",
              " 15: '👍',\n",
              " 16: '👀',\n",
              " 17: '😊',\n",
              " 18: '😍',\n",
              " 19: '😂'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku7y2RTR2bwq"
      },
      "source": [
        "res = pd.DataFrame()\n",
        "res[\"Emoji\"] = inv_voc.values()\n",
        "res[\"precision\"] = precision\n",
        "res[\"recall\"] = recall\n",
        "res[\"f_score\"] = f_score"
      ],
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "nMJ77J3b2rOB",
        "outputId": "af204c84-1c78-4fe3-9f56-07b9f9f02bd2"
      },
      "source": [
        "res"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Emoji</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>💪</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.246914</td>\n",
              "      <td>0.320000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>👊</td>\n",
              "      <td>0.371134</td>\n",
              "      <td>0.169014</td>\n",
              "      <td>0.232258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>🙌</td>\n",
              "      <td>0.407407</td>\n",
              "      <td>0.053140</td>\n",
              "      <td>0.094017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>🙏</td>\n",
              "      <td>0.491736</td>\n",
              "      <td>0.445693</td>\n",
              "      <td>0.467583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>❤</td>\n",
              "      <td>0.626168</td>\n",
              "      <td>0.241877</td>\n",
              "      <td>0.348958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>😜</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>👏</td>\n",
              "      <td>0.457143</td>\n",
              "      <td>0.268156</td>\n",
              "      <td>0.338028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>🔥</td>\n",
              "      <td>0.651515</td>\n",
              "      <td>0.552463</td>\n",
              "      <td>0.597914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>😎</td>\n",
              "      <td>0.417021</td>\n",
              "      <td>0.168966</td>\n",
              "      <td>0.240491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>😁</td>\n",
              "      <td>0.368421</td>\n",
              "      <td>0.012704</td>\n",
              "      <td>0.024561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>😉</td>\n",
              "      <td>0.322129</td>\n",
              "      <td>0.159280</td>\n",
              "      <td>0.213160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>🎉</td>\n",
              "      <td>0.542955</td>\n",
              "      <td>0.714932</td>\n",
              "      <td>0.617187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>💯</td>\n",
              "      <td>0.540625</td>\n",
              "      <td>0.480556</td>\n",
              "      <td>0.508824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>👌</td>\n",
              "      <td>0.422794</td>\n",
              "      <td>0.282209</td>\n",
              "      <td>0.338484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>😘</td>\n",
              "      <td>0.464960</td>\n",
              "      <td>0.389391</td>\n",
              "      <td>0.423833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>👍</td>\n",
              "      <td>0.453654</td>\n",
              "      <td>0.487548</td>\n",
              "      <td>0.469991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>👀</td>\n",
              "      <td>0.548558</td>\n",
              "      <td>0.488184</td>\n",
              "      <td>0.516613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>😊</td>\n",
              "      <td>0.376783</td>\n",
              "      <td>0.456224</td>\n",
              "      <td>0.412716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>😍</td>\n",
              "      <td>0.542152</td>\n",
              "      <td>0.633980</td>\n",
              "      <td>0.584482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>😂</td>\n",
              "      <td>0.663419</td>\n",
              "      <td>0.853464</td>\n",
              "      <td>0.746537</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Emoji  precision    recall   f_score\n",
              "0      💪   0.454545  0.246914  0.320000\n",
              "1      👊   0.371134  0.169014  0.232258\n",
              "2      🙌   0.407407  0.053140  0.094017\n",
              "3      🙏   0.491736  0.445693  0.467583\n",
              "4      ❤   0.626168  0.241877  0.348958\n",
              "5      😜   0.000000  0.000000  0.000000\n",
              "6      👏   0.457143  0.268156  0.338028\n",
              "7      🔥   0.651515  0.552463  0.597914\n",
              "8      😎   0.417021  0.168966  0.240491\n",
              "9      😁   0.368421  0.012704  0.024561\n",
              "10     😉   0.322129  0.159280  0.213160\n",
              "11     🎉   0.542955  0.714932  0.617187\n",
              "12     💯   0.540625  0.480556  0.508824\n",
              "13     👌   0.422794  0.282209  0.338484\n",
              "14     😘   0.464960  0.389391  0.423833\n",
              "15     👍   0.453654  0.487548  0.469991\n",
              "16     👀   0.548558  0.488184  0.516613\n",
              "17     😊   0.376783  0.456224  0.412716\n",
              "18     😍   0.542152  0.633980  0.584482\n",
              "19     😂   0.663419  0.853464  0.746537"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTYkczaeuSz9"
      },
      "source": [
        "## Manual testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLOlvqJYP0DL"
      },
      "source": [
        "def predict_emoji(model, sentence, voc):\n",
        "    model.eval()\n",
        "    text = tokenizer.encode(sentence, add_special_tokens = True, max_length=128, padding= \"max_length\", truncation = True, return_tensors = \"pt\")\n",
        "    attention_mask = text > 0\n",
        "    attention_mask = attention_mask.squeeze().to(device)\n",
        "    text = text.to(device)\n",
        "    bind = (text, attention_mask)\n",
        "    #print(text, attention_mask)\n",
        "    with torch.no_grad():\n",
        "      outputs = model(bind[0], bind[1])[0]\n",
        "    prediction, indices = torch.topk(torch.sigmoid(outputs), 1)\n",
        "    indices = indices.detach().cpu().numpy()\n",
        "    mojis = [voc[pred]for pred in indices[0]]\n",
        "    return mojis\n",
        "\n",
        "    \n"
      ],
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwHMmBjUS4bZ"
      },
      "source": [
        "inv_voc = {}\n",
        "for m in labs:\n",
        "  inv_voc[labs[m]] = m\n",
        "inv_voc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxI4x32irPeq"
      },
      "source": [
        "eval = eval.reset_index(drop=True)\n"
      ],
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRhu8aniUCJS",
        "outputId": "ff3e54d1-4ff8-4755-a048-641cd6c969ff"
      },
      "source": [
        "for i in range(eval.shape[0]):\n",
        "  print(eval[\"Line\"][i].split(\".\")[0])\n",
        "  print(predict_emoji(model, eval[\"Line\"][i].split(\".\")[0], inv_voc), eval[\"Emoji\"][i])"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Two hands placed firmly together, meaning please or thank you in Japanese culture\n",
            "['😊'] 🙏\n",
            "Two hands raised in the air, celebrating success or another joyous event\n",
            "['🎉'] 🙌\n",
            "A face showing a stuck-out tongue, winking at the same time\n",
            "['😂'] 😜\n",
            "An emoji face blowing a kiss; but officially called “Face Throwing A Kiss”\n",
            "['😂'] 😘\n",
            "A face smiling and wearing dark sunglasses that is used to denote a sense of cool\n",
            "['😎'] 😎\n",
            "A face with hearts instead of eyes, or Heart Eyes Emoji as it is generally known\n",
            "['😍'] 😍\n",
            "A smiling face, with smiling eyes and rosy cheeks\n",
            "['😊'] 😊\n",
            "A classic winky emoji; winking and smiling\n",
            "['😊'] 😉\n",
            "A laughing emoji which at small sizes is often mistaken for being tears of sadness\n",
            "['😂'] 😂\n",
            "A version of the grinning face showing smiling eyes\n",
            "['😂'] 😁\n",
            "A classic red love heart emoji, used to express love\n",
            "['😍'] ❤\n",
            "A small flame, mostly yellow but red at the top\n",
            "['🔥'] 🔥\n",
            "100 emoji: the number one-hundred, written in red, underlined twice for emphasis\n",
            "['👌'] 💯\n",
            "An arm flexing to show its biceps muscle\n",
            "['💪'] 💪\n",
            "Two hands clapping emoji, which when used multiple times can be used as a round of applause\n",
            "['👏'] 👏\n",
            "A thumbs-up gesture indicating approval\n",
            "['😊'] 👍\n",
            "Index finger touching thumb to make an open circle\n",
            "['😂'] 👌\n",
            "A fist displayed in a position to punch someone, or to fist-bump another person\n",
            "['👊'] 👊\n",
            "A pair of eyes, glancing slightly to the left on most platforms\n",
            "['👀'] 👀\n",
            "A colorful party popper, used for party or other celebration\n",
            "['🎉'] 🎉\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNF_oXevuW5Y"
      },
      "source": [
        "## Saving and loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiPRjiUT421s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8d4f6bd-5a70-4227-f450-f50d609b86ae"
      },
      "source": [
        "\n",
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "#output_dir = '/content/drive/My Drive/NLP/Data/bert_mc_20'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "#torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to /content/drive/My Drive/NLP/Data/bert_mc_20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/My Drive/NLP/Data/bert_mc_20/tokenizer_config.json',\n",
              " '/content/drive/My Drive/NLP/Data/bert_mc_20/special_tokens_map.json',\n",
              " '/content/drive/My Drive/NLP/Data/bert_mc_20/vocab.txt',\n",
              " '/content/drive/My Drive/NLP/Data/bert_mc_20/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh7qN9t-6WIT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a45dafcd-bb58-49f1-b93d-f7700f0d4bda"
      },
      "source": [
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "\n",
        "output_dir = '/content/drive/My Drive/NLP/Data/bert_twitter'\n",
        "model = DistilBertForSequenceClassification.from_pretrained(output_dir)\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (1): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (2): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (3): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (4): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (5): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=20, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8NxSSfP6mrK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}